hosts = cluster.yarn.nodemanager.hosts.all()
max_cores = 0
max_memory = 0
for key in hosts:
    if hosts[key].numCores > max_cores:
        max_cores = hosts[key].numCores
    if hosts[key].totalPhysMemBytes > max_memory:
        max_memory = hosts[key].totalPhysMemBytes

CORES_PER_WORKER_NODE = max_cores
TOTAL_MEMORY_PER_WORKER_NODE_GIB = max_memory
NUMBER_OF_WORKER_NODES = len(hosts)
MAX_HBASE_MEMORY_MiB = cluster.hbase.regionserver.regionserver_base.hbase_regionserver_java_heapsize.value

MEMORY_FRACTION_RESERVED_FOR_HBASE=0.2
MEMORY_FRACTION_RESERVED_FOR_SPARK=0
NUMBER_OF_CONCURRENT_THREADS=1



TOTAL_MEMORY_PER_WORKER_NODE_MiB = TOTAL_MEMORY_PER_WORKER_NODE_GIB * 1024
RESOURCE_FRACTION_RESERVED_FOR_All_OTHER_SERVICES = 0.2
RESOURCE_OVERCOMMIT_VALIDATION_THRESHOLD=0.8
CORES_RESERVED_FOR_All_OTHER_SERVICES = CORES_PER_WORKER_NODE * RESOURCE_FRACTION_RESERVED_FOR_All_OTHER_SERVICES
MEMORY_RESERVED_FOR_All_OTHER_SERVICES = TOTAL_MEMORY_PER_WORKER_NODE_MiB * RESOURCE_FRACTION_RESERVED_FOR_All_OTHER_SERVICES
TOTAL_USABLE_CORES_PER_WORKER_NODE = CORES_PER_WORKER_NODE - CORES_RESERVED_FOR_All_OTHER_SERVICES
TOTAL_USABLE_MEMORY_PER_WORKER_NODE_MiB = TOTAL_MEMORY_PER_WORKER_NODE_MiB - MEMORY_RESERVED_FOR_All_OTHER_SERVICES
TOTAL_ALLOCATABLE_CORES_PER_WORKER_NODE_MiB = TOTAL_USABLE_CORES_PER_WORKER_NODE
TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_MiB = TOTAL_USABLE_MEMORY_PER_WORKER_NODE_MiB * RESOURCE_OVERCOMMIT_VALIDATION_THRESHOLD
MEMORY_FRACTION_RESERVED_FOR_YARN = 0.8
TOTAL_ALLOCATABLE_MEMORY_FOR_HBASE_PER_WORKER_NODE_MiB = TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_MiB * MEMORY_FRACTION_RESERVED_FOR_HBASE
TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_FINAL_MiB = TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_MiB + (TOTAL_ALLOCATABLE_MEMORY_FOR_HBASE_PER_WORKER_NODE_MiB - MAX_HBASE_MEMORY_MiB if TOTAL_ALLOCATABLE_MEMORY_FOR_HBASE_PER_WORKER_NODE_MiB >MAX_HBASE_MEMORY_MiB else 0)
TOTAL_ALLOCATABLE_MEMORY_FOR_SPARK_PER_WORKER_NODE_MiB = TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_MiB * MEMORY_FRACTION_RESERVED_FOR_SPARK
TOTAL_ALLOCATABLE_MEMORY_FOR_YARN_PER_WORKER_NODE_MiB = TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_FINAL_MiB * MEMORY_FRACTION_RESERVED_FOR_YARN


#TOTAL_ALLOCATABLE_MEMORY_PER_WORKER_NODE_FINAL_MiB
#TOTAL_ALLOCATABLE_MEMORY_FOR_YARN_PER_WORKER_NODE_MiB= *MEMORY_FRACTION_RESERVED_FOR_YARN
cdh = { }
cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_JAVA_OPTS_MAX_HEAP"] = int(float(cluster.yarn.gateway.gateway_base.mapreduce_map_memory_mb.value) * RESOURCE_OVERCOMMIT_VALIDATION_THRESHOLD)
cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_REDUCE_JAVA_OPTS_MAX_HEAP"] = int(2 * cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_JAVA_OPTS_MAX_HEAP"])
cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"] = int(TOTAL_ALLOCATABLE_MEMORY_FOR_YARN_PER_WORKER_NODE_MiB/TOTAL_ALLOCATABLE_CORES_PER_WORKER_NODE_MiB)
cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_REDUCE_MEMORY_MB"] = int(2 * cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"])
cdh["YARN.RESOURCEMANAGER.RESOURCEMANAGER_BASE.YARN_SCHEDULER_MINIMUM_ALLOCATION_MB"] = cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"]
cdh["YARN.RESOURCEMANAGER.RESOURCEMANAGER_BASE.YARN_SCHEDULER_MAXIMUM_ALLOCATION_MB"] = TOTAL_ALLOCATABLE_MEMORY_FOR_YARN_PER_WORKER_NODE_MiB
cdh["YARN.NODEMANAGER.NODEMANAGER_BASE.YARN_NODEMANAGER_RESOURCE_MEMORY_MB"] = TOTAL_ALLOCATABLE_MEMORY_FOR_YARN_PER_WORKER_NODE_MiB

CONTAINERS_ACCROSS_CLUSTER = int(((cdh["YARN.NODEMANAGER.NODEMANAGER_BASE.YARN_NODEMANAGER_RESOURCE_MEMORY_MB"]/cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"]) - 2) * NUMBER_OF_WORKER_NODES - 2)
GIRAPH_WORKERS_ACCROSS_CLUSTER = int(((cdh["YARN.NODEMANAGER.NODEMANAGER_BASE.YARN_NODEMANAGER_RESOURCE_MEMORY_MB"]/cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"]) - 2) * NUMBER_OF_WORKER_NODES - 2)

atk = {}
atk["intel.taproot.analytics.engine.spark.conf.properties.spark.executor.memory"] = cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"]
atk["intel.taproot.analytics.engine.spark.conf.properties.spark.yarn.numexecutors"] = int(CONTAINERS_ACCROSS_CLUSTER/NUMBER_OF_CONCURRENT_THREADS)
atk["intel.taproot.analytics.api.giraph.giraph.maxworkers"] = int(CONTAINERS_ACCROSS_CLUSTER/NUMBER_OF_CONCURRENT_THREADS)
atk["intel.taproot.analytics.api.giraph.mapreduce.map.memory.mb"] = cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_MEMORY_MB"]
atk["intel.taproot.analytics.api.giraph.mapreduce.map.java.opts.max.heap"] = cdh["YARN.GATEWAY.GATEWAY_BASE.MAPREDUCE_MAP_JAVA_OPTS_MAX_HEAP"]



